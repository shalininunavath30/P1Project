{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sn\n",
    "import getpass\n",
    "\n",
    "spark=SparkSession.builder.appName('demo').getOrCreate() \n",
    "bank_data=spark.read.csv(\"bank_segdata.csv\",inferSchema=True,header=True)\n",
    "\n",
    "\n",
    "def run_query(query_number):\n",
    "    if query_number == 1:\n",
    "        df.filter((df[\"CustAccountBalance\"]>500) & (df[\"TransactionAmount\"]<50000)).show()\n",
    "        run()\n",
    "        \n",
    "    elif query_number == 2:\n",
    "        df.filter(df[\"CustGender\"] == \"F\").selectExpr(\"avg(CustAccountBalance)\").show() \n",
    "        run()\n",
    "    \n",
    "    elif query_number == 3:\n",
    "        result = df.filter((df[\"CustGender\"]==\"F\") & (df[\"CustLocation\"]==\"CHENNAI\")).show() \n",
    "        run()\n",
    "    \n",
    "    elif query_number == 4:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from pyspark.sql.functions import sum\n",
    "        total_transactions = bank_data.groupBy(\"CustGender\").agg(sum(\"TransactionAmount\").alias(\"total_transaction_amount\")).toPandas()\n",
    "        print(total_transactions.head())\n",
    "\n",
    "        sn.set(rc={'figure.figsize':(6,5)})\n",
    "        sn.barplot(data=total_transactions, x='CustGender', y='total_transaction_amount')\n",
    "        plt.title('Total Transaction Amount by Gender')\n",
    "        plt.xlabel('Gender')\n",
    "        plt.ylabel('Total Transaction Amount')\n",
    "        plt.show()\n",
    "        run()\n",
    "    elif query_number == 5:\n",
    "        from pyspark.sql.functions import max\n",
    "\n",
    "        highest_transactions = df.filter(df[\"CustLocation\"] == \"MUMBAI\") \\\n",
    "                             .groupBy(\"TransactionDate\") \\\n",
    "                             .agg(max(\"TransactionAmount\").alias(\"HighestTransactionAmount\"))\n",
    "\n",
    "        highest_transactions.show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 6:\n",
    "        df.select(\"TransactionAmount\").agg({\"TransactionAmount\": \"avg\"}).show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 7:\n",
    "        df.select(\"TransactionAmount\").agg({\"TransactionAmount\": \"max\"}).show() \n",
    "        run()\n",
    "        \n",
    "    elif query_number == 8:\n",
    "        df.select(\"TransactionAmount\").agg({\"TransactionAmount\": \"min\"}).show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 9:\n",
    "        from pyspark.sql.functions import desc\n",
    "\n",
    "\n",
    "        sorted_transactions = df.sort(desc(\"TransactionAmount\"))\n",
    "\n",
    "\n",
    "        highest_transaction = sorted_transactions.first()\n",
    "        print(\"TransctionID:\", highest_transaction.TransctionID)\n",
    "        print(\"Amount:\", highest_transaction.TransactionAmount)\n",
    "        run()\n",
    "    elif query_number == 10:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        from pyspark.sql.functions import sum\n",
    "        total_transactions = bank_data.groupBy(\"CustomerID\").agg(sum(\"TransactionAmount\").alias(\"total_transaction_amount\")).toPandas()\n",
    "        print(total_transactions.head())\n",
    "\n",
    "        sn.set(rc={'figure.figsize':(16,8)})\n",
    "        sn.barplot(data=total_transactions, x='CustomerID', y='total_transaction_amount')\n",
    "        plt.title('Total Transaction Amount by Customer ID')\n",
    "        plt.xlabel('Customer ID')\n",
    "        plt.ylabel('Total Transaction Amount')\n",
    "        plt.show()\n",
    "        run()\n",
    "    elif query_number == 11:\n",
    "        from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "        count = df.filter(col(\"TransactionDate\") == \"21-10-2016\").show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 12:\n",
    "        from pyspark.sql.functions import col, sum\n",
    "\n",
    "\n",
    "        filtered_transactions_df = df.filter(col(\"TransactionDate\").between(\"03-08-2016\", \"21-10-2016\"))\n",
    "\n",
    "\n",
    "        filtered_transactions_df.show()\n",
    "        run()\n",
    "    elif query_number == 13:\n",
    "        df.orderBy(\"CustAccountBalance\", ascending=False).show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 14:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from pyspark.sql.functions import sum\n",
    "        total_transactions = bank_data.groupBy(\"CustLocation\").agg(sum(\"TransactionAmount\").alias(\"total_transaction_amount\")).toPandas()\n",
    "        print(total_transactions.head())\n",
    "\n",
    "        sn.set(rc={'figure.figsize':(12,6)})\n",
    "        sn.barplot(data=total_transactions, x='CustLocation', y='total_transaction_amount')\n",
    "        plt.title('Total Transaction Amount by Customer Location')\n",
    "        plt.xlabel('Customer Location')\n",
    "        plt.ylabel('Total Transaction Amount')\n",
    "        plt.show()\n",
    "        run()\n",
    "    elif query_number == 13:\n",
    "        df.orderBy(\"CustAccountBalance\", ascending=False).show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 14:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from pyspark.sql.functions import sum\n",
    "        total_transactions = bank_data.groupBy(\"CustLocation\").agg(sum(\"TransactionAmount\").alias(\"total_transaction_amount\")).toPandas()\n",
    "        print(total_transactions.head())\n",
    "\n",
    "        sn.set(rc={'figure.figsize':(12,6)})\n",
    "        sn.barplot(data=total_transactions, x='CustLocation', y='total_transaction_amount')\n",
    "        plt.title('Total Transaction Amount by Customer Location')\n",
    "        plt.xlabel('Customer Location')\n",
    "        plt.ylabel('Total Transaction Amount')\n",
    "        plt.show()\n",
    "        run()\n",
    "        \n",
    "    elif query_number == 15:\n",
    "        df.groupBy(\"CustLocation\").agg({\"TransactionAmount\": \"sum\", \"TransctionID\": \"count\"}).show()\n",
    "        run()\n",
    "    \n",
    "    elif query_number == 16:\n",
    "        from pyspark.sql.functions import col, sum\n",
    "\n",
    "        filtered_transactions_df = df.filter(col(\"TransactionTime\").between(\"52256\", \"183144\"))\n",
    "\n",
    "\n",
    "        filtered_transactions_df.show()\n",
    "        customer_balances_df = filtered_transactions_df.groupBy(\"CustomerID\")\\\n",
    "            .agg(sum(\"TransactionAmount\").alias(\"TotalTransactionAmount\"))\\\n",
    "            .join(df.select(\"CustomerID\", \"CustAccountBalance\"), on=\"CustomerID\", how=\"left\")\\\n",
    "            .withColumn(\"CustomerBalance\", col(\"CustAccountBalance\") + col(\"TotalTransactionAmount\"))\n",
    "\n",
    "        customer_balances_df.show()\n",
    "        run()\n",
    "\n",
    "    elif query_number == 17:                                                                     \n",
    "\n",
    "        df.createOrReplaceTempView(\"transactions\")\n",
    "        spark.sql(\"SELECT t1.CustomerID, t1.CustLocation, t1.CustAccountBalance FROM transactions t1 INNER JOIN (SELECT CustLocation, MAX(CustAccountBalance) AS MaxBalance FROM transactions GROUP BY CustLocation) t2 ON t1.CustLocation = t2.CustLocation AND t1.CustAccountBalance = t2.MaxBalance\").show()\n",
    "        run()\n",
    "        \n",
    "    elif query_number == 18:\n",
    "        spark.sql(\"SELECT t1.* FROM transactions t1 INNER JOIN (SELECT CustomerID, AVG(TransactionAmount) AS AvgAmount FROM transactions GROUP BY CustomerID) t2 ON t1.CustomerID = t2.CustomerID WHERE t1.TransactionAmount > t2.AvgAmount\").show() \n",
    "        run()\n",
    "        elif query_number == 19:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from pyspark.sql.functions import desc\n",
    "\n",
    "        \n",
    "        top_10_customers = df.groupBy(\"CustomerID\").agg({\"TransactionAmount\": \"sum\"}) \\\n",
    "                            .orderBy(desc(\"sum(TransactionAmount)\")).limit(10) \\\n",
    "                            .toPandas()\n",
    "        print(top_10_customers.head())\n",
    "\n",
    "        sn.set(rc={'figure.figsize':(10,6)})\n",
    "        sn.barplot(data=top_10_customers, x='CustomerID', y='sum(TransactionAmount)')\n",
    "        plt.title('Top 10 Customers by Transaction Amount')\n",
    "        plt.xlabel('Customer ID')\n",
    "        plt.ylabel('Total Transaction Amount')\n",
    "        plt.show()\n",
    "        run()\n",
    "        else:\n",
    "        print(\"Invalid choice\")  \n",
    "        \n",
    "def run():\n",
    "    \n",
    "    print(''' \n",
    "            1.Number of customers with balance > 500 and transaction amount < 50000: \n",
    "            2. Average account balance of female customers: \n",
    "            3. Female customers located in Chennai: \n",
    "            4. Group customers by gender and show the total transaction amount for each group \n",
    "            5. The highest transaction amount for each day in Mumbai \n",
    "            6. The average transaction amount for all transactions \n",
    "            7. The highest transaction amount \n",
    "            8. The lowest transaction amount \n",
    "            9. The customer with the highest transaction amount \n",
    "            10. Group customers by ID and show the total transaction amount for each group \n",
    "            11. T1ransactions made on a specific date (e.g. \"21-10-2016\") \n",
    "            12. Balance of each customer on a specific date range (e.g. \"03-08-2016\" to \"21-10-2016\") \n",
    "            13. The customers with the highest account balance \n",
    "            14. Group transactions by location and total transaction amount for each group \n",
    "            15. Group transactions by location and the total transaction amount and count for each group \n",
    "            16. Balance of each customer during a specific time range (e.g. \"52256\" to \"183144\") \n",
    "            17. Maximum customer balance for each location \n",
    "            18.Customers who have made transactions larger than their average transaction amoun1t \n",
    "            19.The top 10 customers with the highest TransactionAmount\n",
    "\n",
    "            20. Exit   ''')\n",
    "    \n",
    "     query_number= int(input(\"Enter your choice: \"))\n",
    "       \n",
    "    run_query(query_number)\n",
    "        \n",
    "\n",
    "username = \"Team_titans\"\n",
    "pswd = \"Titans@21\"\n",
    "\n",
    "def login():\n",
    "    a=input(\"enter the user name: \")\n",
    "    b=getpass.getpass(prompt=\"Enter your password:\")\n",
    "    if username==a and pswd==b:\n",
    "        print(\"Logged in Successfully\")\n",
    "        run()\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid User Name Or Password \")\n",
    "        login()\n",
    "login()\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
